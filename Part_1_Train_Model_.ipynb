{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgCxIMfBMvJA"
   },
   "source": [
    "# Face Mask Detection by Live Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dvam161m1lP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn #its help to create and train Neural network\n",
    "import torch.optim as optim #implementing various optimization algorithms\n",
    "from torch.optim import lr_scheduler #learning rate scheduler, we can gradually decrease the learning rate value dynamically while training\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xu32SycoNBZz"
   },
   "outputs": [],
   "source": [
    "## [ 1 ] Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sW_K-AEUnJyQ"
   },
   "outputs": [],
   "source": [
    "experiments_path = 'C:/Users/SIRISHA/Desktop/Face-Mask-Detection-and-Authentication-main/experiements/dest_folder/'\n",
    "data_path = 'C:/Users/SIRISHA/Desktop/Face-Mask-Detection-and-Authentication-main/experiements/data/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3K-cEjvNVZj"
   },
   "source": [
    "## [ 2 ] Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AORf1yn3Pw4H"
   },
   "outputs": [],
   "source": [
    "#train_data = experiments_path+'train'\n",
    "# train_data = datasets.ImageFolder(root = train_dir, \n",
    "#                                   transform = transforms.ToTensor())\n",
    "\n",
    "# means = torch.zeros(3)\n",
    "# stds = torch.zeros(3)\n",
    "\n",
    "# for img, label in train_data:\n",
    "#     means += torch.mean(img, dim = (1,2))\n",
    "#     stds += torch.std(img, dim = (1,2))\n",
    "\n",
    "# means /= len(train_data)\n",
    "# stds /= len(train_data)\n",
    "    \n",
    "# print(f'Calculated means: {means}')\n",
    "# print(f'Calculated stds: {stds}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ao4vQMu2GqF"
   },
   "source": [
    "Now to actually load our data. As we are going to be using a pre-trained model we will need to ensure that our images are the same size and have the same normalization as those used to train the model - which we find on the torchvision models page.\n",
    "\n",
    "We use the same data augmentation as always: randomly rotating, flipping horizontally and cropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aS2am750nP9F"
   },
   "outputs": [],
   "source": [
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224), #crop the images \n",
    "        transforms.ToTensor(),  # image to a pixel with range [0,1]\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) #normalize rgb image in same std and mean\n",
    "    ]), \n",
    "    'test' : transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNeiqs66nXvN"
   },
   "outputs": [],
   "source": [
    "def get_train_files_path(experiments_path, data_path, phase):\n",
    "    if phase == 'train':\n",
    "        file_name = 'train.csv'\n",
    "    elif phase == 'test':\n",
    "        file_name = 'test.csv'\n",
    "    else:\n",
    "        print(\"phase can only have train and test as parameter values\")\n",
    "        exit()\n",
    "        \n",
    "    file_path = os.path.join(experiments_path, file_name)\n",
    "    train_df = pd.read_csv(file_path, delimiter=',')\n",
    "    files_path = []\n",
    "    fonts_class = []\n",
    "    for row in train_df.iterrows():\n",
    "        files_path.append(os.path.join(data_path, row[1]['class'], row[1]['filename']))\n",
    "        fonts_class.append(row[1]['class'])\n",
    "    \n",
    "    return files_path, fonts_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9H-bdXFncaq"
   },
   "outputs": [],
   "source": [
    "def copy_images_to_path(file_path, file_class, destination_dir):\n",
    "    font_folder = os.path.join(destination_dir, file_class)\n",
    "    if os.path.exists(font_folder) == False:\n",
    "        os.makedirs(font_folder)\n",
    "    \n",
    "    print(\"File being copied from {}:{}\".format(file_path, font_folder))\n",
    "    shutil.copy(file_path, font_folder)\n",
    "    #shutil.copyfile(file_path, font_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8zb-Ch0NuWZ"
   },
   "source": [
    "## [ 3 ] Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HFJp-K1Cngro"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_train_files_path(experiments_path, data_path, phase='train')\n",
    "X_test, y_test = get_train_files_path(experiments_path, data_path, phase='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8ZXhSzHnkrz"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(experiments_path, 'train')\n",
    "test_dir = os.path.join(experiments_path, 'test')\n",
    "\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQ90hEVEsO9C",
    "outputId": "6d7179e6-c9fc-418f-df49-fa7249809f82"
   },
   "outputs": [],
   "source": [
    "for file_path, font_class in zip(X_train, y_train):\n",
    "    copy_images_to_path(file_path, font_class, train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ts0hZNZ6nlOQ"
   },
   "outputs": [],
   "source": [
    "image_datasets = {x: datasets.ImageFolder(os.path.join(experiments_path, x), data_transforms[x]) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njdahUN3nlYa",
    "outputId": "f46b4688-e57d-49e0-86de-041a9bbf975f"
   },
   "outputs": [],
   "source": [
    "image_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8h1HCpN6wj4",
    "outputId": "dfc7b9ce-644d-4127-8a3d-a961cda60cb5"
   },
   "outputs": [],
   "source": [
    "image_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6w2s-JSnmTh"
   },
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                             batch_size=16, \n",
    "                                             shuffle=True, \n",
    "                                             num_workers=4) \n",
    "               for x in ['train', 'test']} #works for creating batch of 16 images and work on 4 images at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IKgsLEbnmlh",
    "outputId": "cdf50b01-4a61-453d-ed34-6d3f98d61118"
   },
   "outputs": [],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTHadrpzoK49"
   },
   "outputs": [],
   "source": [
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7V6FjUQoLWo",
    "outputId": "f2ff3982-0530-464b-c196-9cd38fe20836"
   },
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2s0ZFaOnoLi7",
    "outputId": "fa8fe913-c187-4463-ea35-10660331b1fe"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "'''CUDA (an acronym for Compute Unified Device Architecture) is a parallel \n",
    "computing platform and application programming interface (API) model created by Nvidia'''\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQBSDR1loMQn"
   },
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pi8ghH0vokL5"
   },
   "source": [
    "## [ 4 ] Visualizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDdiRmfUoeKf"
   },
   "outputs": [],
   "source": [
    "\n",
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean #optimize input image\n",
    "    inp = np.clip(inp, 0, 1) #taking clip of value 0 to 1\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(inp)\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWcOs48AoMdl"
   },
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "# inputs contains 4 images because batch_size=4 for the dataloaders\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvL0vRW1ozJ-"
   },
   "source": [
    "## [ 5 ] Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fybR7bZMo1EC"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    new_freeze_state = None\n",
    "    prev_freeze_state = False\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "        \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc:{:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            \n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2pysHVkJhzk"
   },
   "source": [
    "### [ 5.1 ] ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82,
     "referenced_widgets": [
      "882895d28b534a848184a79b0784e286",
      "bdd6e99920f84b49a3d777bd4138620a",
      "81f3ce777ff54cafbc4443500b307672",
      "09cecff899b843fe820eeabbb62ee73b",
      "d0c94a5d2fbd44bc81c6d9f6449561c0",
      "c53dc938864b4e459634cfabd8c3c7fe",
      "83db0820518e409eb7c2258ba05d47c7",
      "82c8c42da16046e28cc1232a332a7818",
      "b47ee5e5381e480b923b791d5d6c749b"
     ]
    },
    "id": "Q1xKRSO8o2M0",
    "outputId": "f2e68c8d-55fc-4900-8372-88b61dcab49d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re_model_ft = models.resnet101(pretrained=True)\n",
    "\n",
    "re_num_frts = re_model_ft.fc.in_features\n",
    "re_model_ft.fc = nn.Linear(re_num_frts, len(class_names))\n",
    "\n",
    "re_model_ft = re_model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "''' Adaptive Subgradient Methods (AdaGrad)? AdaGrad is a variation of \n",
    "stochastic gradient optimization algorithms that updates the learning rate for each parameter.'''\n",
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_ft = optim.Adagrad(re_model_ft.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9EMQharIpJqE",
    "outputId": "fc9b6e06-490b-4dfa-ca8d-22bb78c4c6fe"
   },
   "outputs": [],
   "source": [
    "ResNetmodel_ft = train_model(re_model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxkotEDNpdI7"
   },
   "outputs": [],
   "source": [
    "torch.save(ResNetmodel_ft, 'C:/Users/SIRISHA/Desktop/Face-Mask-Detection-and-Authentication-main/maskmodel1_resnet101.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpyD9nB-LLER",
    "outputId": "5b318b40-da0b-4f71-b76a-5830b046eb92"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "nb_classes = 2\n",
    "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = ResNetmodel_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "print(\"============================================\")\n",
    "print(f\"Normalized confusion matrix:\")\n",
    "for row in confusion_matrix:\n",
    "    a = row / row.sum()\n",
    "    n = np.round_(a, decimals = 4)\n",
    "    print(n)\n",
    "print(\"============================================\")\n",
    "class_names = ['with_mask', 'without_mask']\n",
    "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_FEM1B_Ln0n"
   },
   "source": [
    "### [ 5.2 ] AlexNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579,
     "referenced_widgets": [
      "17ea00a9d21642e8992fe1f74344eb4e",
      "7c904cdfe58342f5aa9ab9e5861bc6d0",
      "c66409db54764dedb81255e3e0dde898",
      "425a83609b074600a333f937b1a103b1",
      "0a4f046c7ae345af8a66433caee774b1",
      "28d5664aa65448869acd1ed6a8ca8409",
      "efbe41d7714444b3b871c56afbdba022",
      "32fe5e0b6fe74872be5dc2090ded553f",
      "bf939ce8fdca44e693c49c12a3ac07d1"
     ]
    },
    "id": "cEuAbEj3bTpl",
    "outputId": "572f8a72-8c38-41a4-e8d8-be3ae25f58be"
   },
   "outputs": [],
   "source": [
    "#Now using the AlexNet\n",
    "AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
    "#Model description\n",
    "AlexNet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9dB1-Etbr64"
   },
   "outputs": [],
   "source": [
    "#Updating the second classifier\n",
    "AlexNet_model.classifier[4] = nn.Linear(4096,1024)\n",
    "\n",
    "#Updating the third and the last classifier that is the output layer of the network. Make sure to have 10 output nodes if we are going to get 10 class labels through our model.\n",
    "AlexNet_model.classifier[6] = nn.Linear(1024,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WqGUdrghdewl",
    "outputId": "553a84e5-52ac-4470-e7a9-5930ab328aa4"
   },
   "outputs": [],
   "source": [
    "AlexNet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_fV5uMwdrq1",
    "outputId": "30f21f04-b657-4a52-affa-b9033e27ccab"
   },
   "outputs": [],
   "source": [
    "#Instantiating CUDA device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#Verifying CUDA\n",
    "print(device)\n",
    "#Move the input and AlexNet_model to GPU for speed if available\n",
    "AlexNet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBuSJiz1d4Js"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "#Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#Optimizer(SGD)\n",
    "# optimizer = optim.SGD(AlexNet_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6BK-X5yxqsS"
   },
   "outputs": [],
   "source": [
    "optimizer_ft = optim.Adagrad(AlexNet_model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6sd8rNoXxcE",
    "outputId": "171abd37-1c90-42c2-df39-33885075f7c5"
   },
   "outputs": [],
   "source": [
    "AlexNetmodel_ft = train_model(AlexNet_model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gw2zuhPkqREP"
   },
   "outputs": [],
   "source": [
    "torch.save(AlexNetmodel_ft, 'C:/Users/SIRISHA/Desktop/Face-Mask-Detection-and-Authentication-main/maskmodel2_Alexnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "9wCsK5jzjPsI",
    "outputId": "92576c7d-03a4-408c-8c9c-0550f913a807"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "nb_classes = 2\n",
    "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = AlexNetmodel_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "print(\"============================================\")\n",
    "print(f\"Normalized confusion matrix:\")\n",
    "for row in confusion_matrix:\n",
    "    a = row / row.sum()\n",
    "    n = np.round_(a, decimals = 4)\n",
    "    print(n)\n",
    "print(\"============================================\")\n",
    "class_names = ['with_mask', 'without_mask']\n",
    "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUQ4pYu2OF4H"
   },
   "source": [
    "### [ 5.3 ] GoogleNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdsEKLX-OL-7"
   },
   "outputs": [],
   "source": [
    "go_model_ft = models.googlenet(pretrained=True)\n",
    "\n",
    "go_num_frts = go_model_ft.fc.in_features\n",
    "go_model_ft.fc = nn.Linear(go_num_frts, len(class_names))\n",
    "\n",
    "go_model_ft = go_model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "''' Adaptive Subgradient Methods (AdaGrad)? AdaGrad is a variation of \n",
    "stochastic gradient optimization algorithms that updates the learning rate for each parameter.'''\n",
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_ft = optim.Adagrad(go_model_ft.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCmS0o57imjT",
    "outputId": "1361e2b0-d5b7-48ba-9523-bb04b0d10560"
   },
   "outputs": [],
   "source": [
    "GoogleNetmodel_ft = train_model(go_model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQDXHhlNOTZp"
   },
   "outputs": [],
   "source": [
    "torch.save(GoogleNetmodel_ft, 'C:/Users/SIRISHA/Desktop/Face-Mask-Detection-and-Authentication-main/maskmodel3_GoogleNet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GoogleNetmodel_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install GoogleNetmodel_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCrykPRLPtyG",
    "outputId": "8ea7440c-662b-4183-bde1-4b34e95111e6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "nb_classes = 2\n",
    "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = GoogleNetmodel_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "print(\"============================================\")\n",
    "print(f\"Normalized confusion matrix:\")\n",
    "for row in confusion_matrix:\n",
    "    a = row / row.sum()\n",
    "    n = np.round_(a, decimals = 4)\n",
    "    print(n)\n",
    "print(\"============================================\")\n",
    "class_names = ['with_mask', 'without_mask']\n",
    "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnAkyW4fOTwg"
   },
   "source": [
    "### [ 5.4 ] VGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "8cc39641b4cd4f45a23b98047f1ff0dd"
     ]
    },
    "id": "k9XiC1_oObYZ",
    "outputId": "7573c341-8461-4ae5-fb00-b1d9750a4e39"
   },
   "outputs": [],
   "source": [
    "### Define model\n",
    "vg_model = models.vgg16(pretrained = True)\n",
    "\n",
    "### Modifying last few layers and no of classes\n",
    "# NOTE: cross_entropy loss takes unnormalized op (logits), then function itself applies softmax and calculates loss, so no need to include softmax here\n",
    "vg_model.classifier = nn.Sequential(\n",
    "    nn.Linear(25088, 4096, bias = True),\n",
    "    nn.ReLU(inplace = True),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(4096, 2048, bias = True),\n",
    "    nn.ReLU(inplace = True),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(2048, 200)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qT5fOaEiQGrr"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "vg_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "''' Adaptive Subgradient Methods (AdaGrad)? AdaGrad is a variation of \n",
    "stochastic gradient optimization algorithms that updates the learning rate for each parameter.'''\n",
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_ft = optim.Adagrad(vg_model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ms1Tx54cQJxI",
    "outputId": "179d6f34-c837-4a16-82b2-143e0fc2e87c"
   },
   "outputs": [],
   "source": [
    "Vggmodel_ft = train_model(vg_model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpeEXj0WQS3U"
   },
   "outputs": [],
   "source": [
    "torch.save(Vggmodel_ft, 'C:/Users/SIRISHA/Desktop/Face-Mask-Detection-and-Authentication-main/maskmodel4_vgg.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjz4ztUtQcw_",
    "outputId": "13a290fa-2506-44dd-eed3-f4914dac8e73"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "nb_classes = 2\n",
    "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = Vggmodel_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "print(\"============================================\")\n",
    "print(f\"Normalized confusion matrix:\")\n",
    "for row in confusion_matrix:\n",
    "    a = row / row.sum()\n",
    "    n = np.round_(a, decimals = 4)\n",
    "    print(n)\n",
    "print(\"============================================\")\n",
    "class_names = ['with_mask', 'without_mask']\n",
    "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iwTxY13XUab"
   },
   "source": [
    "## [ 6 ] Visualizing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUFqS2ZVpJ5i"
   },
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    #fig = plt.figure(figsize=(10,10))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            print(preds,\"predicitons\")\n",
    "            \n",
    "            \n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far +=1\n",
    "                #ax = plt.subplot(num_images//len(labels)-1, len(labels), images_so_far)\n",
    "                #ax.axis('off')\n",
    "                #ax.set_title('true: {} predicted: {}'.format(class_names[labels[j]], class_names[preds[j]]))\n",
    "                print('true: {} predicted: {}'.format(class_names[labels[j]], class_names[preds[j]]))\n",
    "                #imshow(inputs.cpu().data[j])\n",
    "                \n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sBeYSuYwphJB",
    "outputId": "4e7668df-4c91-4cd4-d942-13f00635a3b4"
   },
   "outputs": [],
   "source": [
    "visualize_model(ResNetmodel_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kc7-1xhiQvdF",
    "outputId": "cb34841a-0f64-4527-832d-dd61229b3db4"
   },
   "outputs": [],
   "source": [
    "visualize_model(AlexNetmodel_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASTdQndsQyD4",
    "outputId": "92433684-b2c7-41c4-e0a5-568e3be63f13"
   },
   "outputs": [],
   "source": [
    "visualize_model(GoogleNetmodel_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNGewkb4Qxgz",
    "outputId": "27272b6f-1680-48ad-d6ae-56ad0b3bf586"
   },
   "outputs": [],
   "source": [
    "visualize_model(Vggmodel_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Pi8ghH0vokL5"
   ],
   "name": "Part_1_Train_Model .ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09cecff899b843fe820eeabbb62ee73b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82c8c42da16046e28cc1232a332a7818",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_83db0820518e409eb7c2258ba05d47c7",
      "value": " 170M/170M [00:07&lt;00:00, 25.1MB/s]"
     }
    },
    "81f3ce777ff54cafbc4443500b307672": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c53dc938864b4e459634cfabd8c3c7fe",
      "max": 178728960,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0c94a5d2fbd44bc81c6d9f6449561c0",
      "value": 178728960
     }
    },
    "82c8c42da16046e28cc1232a332a7818": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83db0820518e409eb7c2258ba05d47c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "882895d28b534a848184a79b0784e286": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_81f3ce777ff54cafbc4443500b307672",
       "IPY_MODEL_09cecff899b843fe820eeabbb62ee73b"
      ],
      "layout": "IPY_MODEL_bdd6e99920f84b49a3d777bd4138620a"
     }
    },
    "bdd6e99920f84b49a3d777bd4138620a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c53dc938864b4e459634cfabd8c3c7fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0c94a5d2fbd44bc81c6d9f6449561c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
